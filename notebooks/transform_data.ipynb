{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import traceback\n",
    "from utils import map_images_to_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make csv file for AST Feature Extractor (audio segments(10xsong)and valence classes)\n",
    "\n",
    "# create function that splits data train-test-validate based on df(csv) and extracts equal parts of each class---) new dfs\n",
    "\n",
    "# create function that does the same thing but like a dataloader --) nothing new created, only associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.read_csv('../data/processed/1000dataset_valence_cluster.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence_cluster\n",
      "high      386\n",
      "medium    314\n",
      "low       300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#count unique values in column 'valence_cluster'\n",
    "valence_cluster = dfg['valence_cluster'].value_counts()\n",
    "print(valence_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.read_csv('../data/processed/1000dataset_valence_cluster.csv')\n",
    "spec_df_danceability = map_images_to_classes('../data/processed/1000dataset_5/specs', dfg, 'track_id', 'valence_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the class\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "spec_df_danceability['class'] = labelencoder.fit_transform(spec_df_danceability['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_df_danceability.head(6)\n",
    "# save it to csv\n",
    "spec_df_danceability.to_csv('../data/processed/L1000dataset_5seg_valence.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only audio in 'audio' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run move_json_files function\n",
    "#move_json_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transoform audio to spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "\n",
    "def mp3_to_melspectrogram(mp3_file, audio_output_folder, spec_output_folder, trim_seconds=30,\n",
    "                          include_legend=False, nmels=512, segment_duration=5, save_audio_segments=True,\n",
    "                          num_segments=5):\n",
    "    \"\"\"\n",
    "    Converts an MP3 file to mel spectrograms and optionally saves the audio segments.\n",
    "\n",
    "    Parameters:\n",
    "        mp3_file (str): Path to the MP3 file.\n",
    "        audio_output_folder (str): Folder to save the audio segments.\n",
    "        spec_output_folder (str): Folder to save the spectrogram images.\n",
    "        trim_seconds (int): Number of seconds to trim from both ends of the audio.\n",
    "        include_legend (bool): Whether to include legends and axes in the spectrogram plots.\n",
    "        nmels (int): Number of mel bands to generate in the spectrogram.\n",
    "        segment_duration (int): Duration of each segment in seconds. If None, processes the entire audio.\n",
    "        save_audio_segments (bool): Whether to save the corresponding audio segments.\n",
    "        num_segments (int or None): Number of segments to save. If None, saves all segments.\n",
    "    \"\"\"\n",
    "    # Ensure both output folders exist\n",
    "    os.makedirs(audio_output_folder, exist_ok=True)\n",
    "    os.makedirs(spec_output_folder, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading file: {mp3_file}\")\n",
    "\n",
    "        # Load the MP3 file using PyDub\n",
    "        audio = AudioSegment.from_file(mp3_file)\n",
    "        total_duration_ms = len(audio)  # Duration in milliseconds\n",
    "        total_duration = total_duration_ms / 1000.0  # Convert to seconds\n",
    "        print(f\"File {mp3_file}, Total Duration: {total_duration:.2f} seconds\")\n",
    "\n",
    "        # Check if the file is long enough to trim\n",
    "        if total_duration <= 2 * trim_seconds:\n",
    "            print(f\"File {mp3_file} is too short to trim {trim_seconds} seconds from both ends. Skipping.\")\n",
    "            return\n",
    "\n",
    "        # Trim the first and last trim_seconds\n",
    "        start_trim = trim_seconds * 1000  # Convert to milliseconds\n",
    "        end_trim = total_duration_ms - trim_seconds * 1000\n",
    "        audio_trimmed = audio[start_trim:end_trim]\n",
    "\n",
    "        print(f\"Trimmed audio length (ms): {len(audio_trimmed)}\")\n",
    "\n",
    "        # Calculate segment length in samples if segment_duration is specified\n",
    "        sr = audio_trimmed.frame_rate\n",
    "        samples_per_segment = int(segment_duration * sr) if segment_duration else len(audio_trimmed.get_array_of_samples())\n",
    "\n",
    "        # Convert to NumPy array\n",
    "        y = np.array(audio_trimmed.get_array_of_samples()).astype(np.float32)\n",
    "\n",
    "        # Convert stereo to mono\n",
    "        if audio_trimmed.channels == 2:\n",
    "            y = y.reshape((-1, 2)).mean(axis=1)\n",
    "\n",
    "        print(f\"Sample rate: {sr}, Audio shape after conversion: {y.shape}\")\n",
    "\n",
    "        # Determine the total number of segments\n",
    "        total_segments = len(y) // samples_per_segment\n",
    "\n",
    "        # Select random segments if num_segments is specified\n",
    "        if num_segments is not None and num_segments < total_segments:\n",
    "            selected_indices = sorted(random.sample(range(total_segments), num_segments))\n",
    "        else:\n",
    "            selected_indices = list(range(total_segments))\n",
    "\n",
    "        print(f\"Total segments: {total_segments}, Selected segments: {len(selected_indices)}\")\n",
    "\n",
    "        # Process each selected segment\n",
    "        for segment_count, idx in enumerate(selected_indices, start=1):\n",
    "            start_sample = idx * samples_per_segment\n",
    "            segment = y[start_sample:start_sample + samples_per_segment]\n",
    "\n",
    "            # Generate the mel spectrogram\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=segment, sr=sr, n_mels=nmels)\n",
    "            D = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "            # Plot and save the mel spectrogram\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            librosa.display.specshow(D, sr=sr, x_axis='time' if include_legend else None,\n",
    "                                     y_axis='mel' if include_legend else None, cmap='inferno')\n",
    "\n",
    "            if include_legend:\n",
    "                plt.colorbar(format='%+2.0f dB')  # Add color bar if include_legend is True\n",
    "                plt.title(f'Mel Spectrogram of {os.path.basename(mp3_file)} - Segment {segment_count}')  # Add title\n",
    "            else:\n",
    "                plt.axis('off')  # Turn off axes if include_legend is False\n",
    "                plt.gca().set_position([0, 0, 1, 1])  # Remove any padding/margins\n",
    "\n",
    "            # Save the spectrogram image\n",
    "            output_image_path = os.path.join(\n",
    "                spec_output_folder, f\"{os.path.splitext(os.path.basename(mp3_file))[0]}_segment_{segment_count}.png\"\n",
    "            )\n",
    "            plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0 if not include_legend else 0.1)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Spectrogram saved to {output_image_path}\")\n",
    "\n",
    "            # Save the corresponding audio segment if required\n",
    "            if save_audio_segments:\n",
    "                audio_segment = audio_trimmed[start_sample // sr * 1000:(start_sample + samples_per_segment) // sr * 1000]\n",
    "                audio_segment_path = os.path.join(\n",
    "                    audio_output_folder, f\"{os.path.splitext(os.path.basename(mp3_file))[0]}_segment_{segment_count}.mp3\"\n",
    "                )\n",
    "                audio_segment.export(audio_segment_path, format=\"mp3\")\n",
    "                print(f\"Audio segment saved to {audio_segment_path}\")\n",
    "\n",
    "        # Explicitly release memory\n",
    "        del audio, audio_trimmed, y, segment\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {mp3_file}: {e}\")\n",
    "        traceback.print_exc()  # Print detailed error traceback\n",
    "        \n",
    "def process_all_mp3_in_folder(folder_path, audio_output_folder, spec_output_folder):\n",
    "    # Ensure the output folders exist\n",
    "    os.makedirs(audio_output_folder, exist_ok=True)\n",
    "    os.makedirs(spec_output_folder, exist_ok=True)\n",
    "\n",
    "    # Loop through all MP3 files in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".mp3\"):\n",
    "            mp3_file = os.path.join(folder_path, file)\n",
    "\n",
    "            # Check if the first spectrogram segment exists\n",
    "            first_segment_path = os.path.join(\n",
    "                spec_output_folder, f\"{os.path.splitext(file)[0]}_segment_1.png\"\n",
    "            )\n",
    "            if os.path.exists(first_segment_path):\n",
    "                print(f\"Skipping {mp3_file}, spectrogram already exists.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing file: {mp3_file}\")\n",
    "            mp3_to_melspectrogram(mp3_file, audio_output_folder, spec_output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_mp3_in_folder(\"../data/raw/1000dataset\", \"../data/processed/1000dataset_5/audio\", \"../data/processed/1000dataset_5/audio_specs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for processing multiple MP3 files\n",
    "folder_path = \"../data/raw/1000dataset\"  # Folder containing MP3 files\n",
    "#output_folder = \"../data/raw/1000_mel_spectrograms\"  # Folder to save spectrogram images\n",
    "output_folder = \"../data/processed/1000_melspec_5seg_png\"  # Folder to save segmented spectrogram images\n",
    "process_all_mp3_in_folder(folder_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legend and segment parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text to jsonl form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '3odrUVQ9tvRpkC9II2oWzx_segment_5.png',\n",
       " 'additional_feature': 'Ellie Goulding electro'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {\"file_name\" : \"3odrUVQ9tvRpkC9II2oWzx_segment_5.png\", \"additional_feature\": \"Ellie Goulding electro\"}\n",
    "# So if the str before the first underscore is the same to the row track_id column, then add text to the additional feature column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENT SPECTOGRAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform audio and segment spectograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform spectogram to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Function to convert spectrogram to audio and save it as MP3\n",
    "def spectrogram_to_mp3(spec, sr, filename=\"output.mp3\"):\n",
    "    # Step 1: Invert the spectrogram to a time-domain audio signal\n",
    "    # If the spectrogram is in dB, first convert back to amplitude\n",
    "    if np.max(spec) < 0:  # Checking if it's in dB scale\n",
    "        spec = librosa.db_to_amplitude(spec)\n",
    "    \n",
    "    # If the spectrogram is a magnitude spectrogram, use librosa's inverse STFT\n",
    "    audio_signal = librosa.istft(spec)\n",
    "    \n",
    "    # Step 2: Save the audio signal as a WAV file\n",
    "    librosa.output.write_wav(\"temp.wav\", audio_signal, sr)\n",
    "    \n",
    "    # Step 3: Convert WAV to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(\"temp.wav\")\n",
    "    sound.export(filename, format=\"mp3\")\n",
    "    \n",
    "    print(f\"Saved MP3 as {filename}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load an example audio file to create a spectrogram\n",
    "    y, sr = librosa.load(librosa.example('trumpet'))\n",
    "    \n",
    "    # Generate a spectrogram from the audio signal\n",
    "    spec = librosa.stft(y)\n",
    "    spec_db = librosa.amplitude_to_db(np.abs(spec), ref=np.max)\n",
    "    \n",
    "    # Convert the spectrogram back to MP3\n",
    "    spectrogram_to_mp3(spec_db, sr, filename=\"output.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK FROM SPECTOGRAM TO MP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"raw/spectrograms/0A0RBBTrgfq9eClnw6ZXT7.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf  # For saving audio files\n",
    "\n",
    "def image_to_spectrogram(image_path):\n",
    "    \"\"\"\n",
    "    Convert a spectrogram image to a numerical array representing the spectrogram.\n",
    "    Assumes the spectrogram is grayscale, where pixel intensity represents dB values.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(image_path).convert(\"L\")  # Convert to grayscale ('L' mode)\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Normalize the image to [0, 1] range (0 is minimum, 255 is maximum)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Convert the image intensities to dB scale (assuming they represent dB)\n",
    "    # Rescale from [0, 1] to [-80 dB, 0 dB], as typical dB range for spectrograms is -80 to 0\n",
    "    img_db = img_array * -80\n",
    "    \n",
    "    return img_db\n",
    "\n",
    "def spectrogram_to_audio(spectrogram_db, sr=22050, hop_length=512):\n",
    "    \"\"\"\n",
    "    Invert a dB-scaled spectrogram back to an audio waveform.\n",
    "    \"\"\"\n",
    "    # Convert dB to amplitude\n",
    "    spectrogram_amplitude = librosa.db_to_amplitude(spectrogram_db)\n",
    "    \n",
    "    # Perform the inverse Short-Time Fourier Transform (ISTFT) to recover the audio signal\n",
    "    audio_signal = librosa.griffinlim(spectrogram_amplitude, hop_length=hop_length)\n",
    "    \n",
    "    return audio_signal\n",
    "\n",
    "def save_as_mp3(audio_signal, sr, filename=\"output.mp3\"):\n",
    "    \"\"\"\n",
    "    Save the audio signal as an MP3 file using pydub.\n",
    "    \"\"\"\n",
    "    # Save the audio signal as a temporary WAV file using soundfile\n",
    "    sf.write(\"temp.wav\", audio_signal, sr)  # Use soundfile to save as WAV\n",
    "    \n",
    "    # Convert the WAV file to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(\"temp.wav\")\n",
    "    sound.export(filename, format=\"mp3\")\n",
    "    print(f\"Saved MP3 as {filename}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the spectrogram image (PNG)\n",
    "    image_path = \"raw/spectrograms/0A0RBBTrgfq9eClnw6ZXT7.png\"\n",
    "    \n",
    "    # Step 1: Convert the image to a spectrogram\n",
    "    spectrogram_db = image_to_spectrogram(image_path)\n",
    "    \n",
    "    # Step 2: Convert the spectrogram to an audio signal\n",
    "    audio_signal = spectrogram_to_audio(spectrogram_db, sr=22050)\n",
    "    \n",
    "    # Step 3: Save the audio signal as MP3\n",
    "    save_as_mp3(audio_signal, sr=22050, filename=\"output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio shape ???\n",
    "sample rate ???\n",
    "\n",
    "Download everything in wav? or find a solution in another way ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
